{
    "name": "root",
    "gauges": {
        "MoveToGoal.Policy.Entropy.mean": {
            "value": 0.6139107942581177,
            "min": 0.44902369379997253,
            "max": 1.6080851554870605,
            "count": 422
        },
        "MoveToGoal.Policy.Entropy.sum": {
            "value": 3064.642578125,
            "min": 2246.91455078125,
            "max": 8047.88427734375,
            "count": 422
        },
        "MoveToGoal.Step.mean": {
            "value": 2109946.0,
            "min": 4936.0,
            "max": 2109946.0,
            "count": 422
        },
        "MoveToGoal.Step.sum": {
            "value": 2109946.0,
            "min": 4936.0,
            "max": 2109946.0,
            "count": 422
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.mean": {
            "value": 0.061784423887729645,
            "min": -0.9001395106315613,
            "max": 1.1371749639511108,
            "count": 422
        },
        "MoveToGoal.Policy.ExtrinsicValueEstimate.sum": {
            "value": 5.0663228034973145,
            "min": -349.6671142578125,
            "max": 152.38143920898438,
            "count": 422
        },
        "MoveToGoal.Policy.CuriosityValueEstimate.mean": {
            "value": 0.1455429643392563,
            "min": 0.11022448539733887,
            "max": 2.666393518447876,
            "count": 422
        },
        "MoveToGoal.Policy.CuriosityValueEstimate.sum": {
            "value": 11.934523582458496,
            "min": 10.800881385803223,
            "max": 917.9614868164062,
            "count": 422
        },
        "MoveToGoal.Environment.EpisodeLength.mean": {
            "value": 904.1428571428571,
            "min": 11.792307692307693,
            "max": 22380.0,
            "count": 366
        },
        "MoveToGoal.Environment.EpisodeLength.sum": {
            "value": 6329.0,
            "min": 644.0,
            "max": 35010.0,
            "count": 366
        },
        "MoveToGoal.Environment.CumulativeReward.mean": {
            "value": 0.7142852669136346,
            "min": -1.0000111679996841,
            "max": 0.9999997866666727,
            "count": 367
        },
        "MoveToGoal.Environment.CumulativeReward.sum": {
            "value": 4.999996868395442,
            "min": -382.0,
            "max": 9.99999609600011,
            "count": 367
        },
        "MoveToGoal.Policy.ExtrinsicReward.mean": {
            "value": 0.7142852669136346,
            "min": -1.0000111679996841,
            "max": 0.9999997866666727,
            "count": 367
        },
        "MoveToGoal.Policy.ExtrinsicReward.sum": {
            "value": 4.999996868395442,
            "min": -382.0,
            "max": 9.99999609600011,
            "count": 367
        },
        "MoveToGoal.Policy.CuriosityReward.mean": {
            "value": 1.3107992382054883,
            "min": 0.0,
            "max": 40.41862304508686,
            "count": 367
        },
        "MoveToGoal.Policy.CuriosityReward.sum": {
            "value": 9.175594667438418,
            "min": 0.0,
            "max": 1146.8634301275015,
            "count": 367
        },
        "MoveToGoal.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 422
        },
        "MoveToGoal.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 422
        },
        "MoveToGoal.Losses.PolicyLoss.mean": {
            "value": 0.02420669243050118,
            "min": 0.01394300777465105,
            "max": 0.030977014126256107,
            "count": 205
        },
        "MoveToGoal.Losses.PolicyLoss.sum": {
            "value": 0.02420669243050118,
            "min": 0.01394300777465105,
            "max": 0.030977014126256107,
            "count": 205
        },
        "MoveToGoal.Losses.ValueLoss.mean": {
            "value": 0.0036225477078308662,
            "min": 0.00011829777067760006,
            "max": 2.6228246013323466,
            "count": 205
        },
        "MoveToGoal.Losses.ValueLoss.sum": {
            "value": 0.0036225477078308662,
            "min": 0.00011829777067760006,
            "max": 2.6228246013323466,
            "count": 205
        },
        "MoveToGoal.Policy.LearningRate.mean": {
            "value": 0.0002987368744210419,
            "min": 0.0002987368744210419,
            "max": 0.0002999938542020485,
            "count": 205
        },
        "MoveToGoal.Policy.LearningRate.sum": {
            "value": 0.0002987368744210419,
            "min": 0.0002987368744210419,
            "max": 0.0002999938542020485,
            "count": 205
        },
        "MoveToGoal.Policy.Epsilon.mean": {
            "value": 0.199578958,
            "min": 0.199578958,
            "max": 0.19999795140000007,
            "count": 205
        },
        "MoveToGoal.Policy.Epsilon.sum": {
            "value": 0.199578958,
            "min": 0.199578958,
            "max": 0.19999795140000007,
            "count": 205
        },
        "MoveToGoal.Policy.Beta.mean": {
            "value": 0.004978990004199999,
            "min": 0.004978990004199999,
            "max": 0.004999897774860001,
            "count": 205
        },
        "MoveToGoal.Policy.Beta.sum": {
            "value": 0.004978990004199999,
            "min": 0.004978990004199999,
            "max": 0.004999897774860001,
            "count": 205
        },
        "MoveToGoal.Losses.CuriosityForwardLoss.mean": {
            "value": 0.07059839218854905,
            "min": 0.0692222016553084,
            "max": 52.30908616383871,
            "count": 205
        },
        "MoveToGoal.Losses.CuriosityForwardLoss.sum": {
            "value": 0.07059839218854905,
            "min": 0.0692222016553084,
            "max": 52.30908616383871,
            "count": 205
        },
        "MoveToGoal.Losses.CuriosityInverseLoss.mean": {
            "value": 0.08301192832489808,
            "min": 0.06259209302564463,
            "max": 1.1734068036079406,
            "count": 205
        },
        "MoveToGoal.Losses.CuriosityInverseLoss.sum": {
            "value": 0.08301192832489808,
            "min": 0.06259209302564463,
            "max": 1.1734068036079406,
            "count": 205
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1684734501",
        "python_version": "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]",
        "command_line_arguments": "C:\\Users\\ybdto\\OneDrive\\Documents\\unity\\WMMC\\WhoMovedMyCheese\\mlenv\\Scripts\\mlagents-learn config/moveToGoal.yaml --run-id=new --force",
        "mlagents_version": "0.30.0",
        "mlagents_envs_version": "0.30.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.0.0+cpu",
        "numpy_version": "1.21.2",
        "end_time_seconds": "1684749878"
    },
    "total": 15376.8285064,
    "count": 1,
    "self": 0.014497999998638988,
    "children": {
        "run_training.setup": {
            "total": 0.11505120000000035,
            "count": 1,
            "self": 0.11505120000000035
        },
        "TrainerController.start_learning": {
            "total": 15376.6989572,
            "count": 1,
            "self": 38.812607399651824,
            "children": {
                "TrainerController._reset_env": {
                    "total": 14.899650699999999,
                    "count": 1,
                    "self": 14.899650699999999
                },
                "TrainerController.advance": {
                    "total": 15322.881629700349,
                    "count": 2127440,
                    "self": 32.62832440136299,
                    "children": {
                        "env_step": {
                            "total": 13917.168910899385,
                            "count": 2127440,
                            "self": 11917.97022519919,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1971.9252515997969,
                                    "count": 2127440,
                                    "self": 100.27459800097768,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1871.6506535988192,
                                            "count": 2112731,
                                            "self": 1871.6506535988192
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 27.27343410039824,
                                    "count": 2127439,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 15303.312209500255,
                                            "count": 2127439,
                                            "is_parallel": true,
                                            "self": 5259.609253299675,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.006003299999999712,
                                                    "count": 1,
                                                    "is_parallel": true,
                                                    "self": 0.0020465999999998985,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.003956699999999813,
                                                            "count": 2,
                                                            "is_parallel": true,
                                                            "self": 0.003956699999999813
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 10043.696952900578,
                                                    "count": 2127439,
                                                    "is_parallel": true,
                                                    "self": 175.54165680177357,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 170.31920559871264,
                                                            "count": 2127439,
                                                            "is_parallel": true,
                                                            "self": 170.31920559871264
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 9179.074456699524,
                                                            "count": 2127439,
                                                            "is_parallel": true,
                                                            "self": 9179.074456699524
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 518.7616338005677,
                                                            "count": 2127439,
                                                            "is_parallel": true,
                                                            "self": 297.9611738011277,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 220.80045999943997,
                                                                    "count": 4254878,
                                                                    "is_parallel": true,
                                                                    "self": 220.80045999943997
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 1373.0843943996006,
                            "count": 2127439,
                            "self": 45.62674010038177,
                            "children": {
                                "process_trajectory": {
                                    "total": 253.47487919922327,
                                    "count": 2127439,
                                    "self": 253.0351990992221,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.4396801000011692,
                                            "count": 4,
                                            "self": 0.4396801000011692
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1073.9827750999955,
                                    "count": 205,
                                    "self": 908.3524920999904,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 165.6302830000051,
                                            "count": 6150,
                                            "self": 165.6302830000051
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.3999997463542968e-06,
                    "count": 1,
                    "self": 1.3999997463542968e-06
                },
                "TrainerController._save_models": {
                    "total": 0.105068000000756,
                    "count": 1,
                    "self": 0.023460300000806456,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.08160769999994955,
                            "count": 1,
                            "self": 0.08160769999994955
                        }
                    }
                }
            }
        }
    }
}